{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요 라이브러리 호출\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from konlpy.tag import Kkma\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장 함수\n",
    "def save_csv_dict(dicts,filename):\n",
    "    with open(\"excel/\"+filename+\".csv\", 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for k, v in dicts.items():\n",
    "            writer.writerow([k, v])\n",
    "\n",
    "# 상품 구매와 비교적 관계가 없는 단어들 제거 함수\n",
    "except_word=['광고','현금','유저','정도','유료','피파온라인','PC','질문','지금','낙찰','게임','생각','가치','얼마','사람','정보통','대리','이번','후기','이유','요즘', '감사', '시간', '가능', '시간', '진짜', '이상']\n",
    "def count_sort(counter_list,top):\n",
    "    counts={}\n",
    "    i=1\n",
    "    for key, count in dict(sorted(counter_list.items(), key=lambda item: item[1], reverse=True)).items():\n",
    "        if i <= top and key not in except_word:\n",
    "            counts[key]=count\n",
    "            i+=1\n",
    "        elif i>top:\n",
    "            break\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 추출\n",
    "file = open(\"lists/fmko_list.txt\", \"r\", encoding='utf-8')\n",
    "fmko_posts = file.readlines()\n",
    "file.close()\n",
    "\n",
    "posts=[]\n",
    "for i in range(0,len(fmko_posts)-1,2):\n",
    "    tmp=fmko_posts[i].replace('\\n','').split('//구분자//')\n",
    "    if '피파온라인X' not in tmp[0]:\n",
    "        tmp[1]=datetime.strptime(tmp[1],'%Y.%m.%d %H:%M')\n",
    "        tmp[3:6]=list(map(int,tmp[3:6]))\n",
    "        tmp.append(fmko_posts[i+1].replace('\\n','').split('//구분자//'))\n",
    "        posts.append(tmp)\n",
    "\n",
    "posts=sorted(posts,key=lambda x:x[1],reverse=True)\n",
    "\n",
    "posts1=[]\n",
    "comments=[]\n",
    "for post in posts:\n",
    "    posts1.append(post[:6])\n",
    "    comments.append(post[-1])\n",
    "\n",
    "post1=np.array(posts1)\n",
    "main, date, post, view_num, recommend_num, comment_num=post1[:, 0], post1[:, 1], post1[:, 2], post1[:, 3], post1[:, 4], post1[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 게시글 제목, 내용, 댓글별 형태소 분석을 통한 '명사' 및 '외국어' 추출\n",
    "kkma=Kkma()\n",
    "\n",
    "main_noun=[]\n",
    "for main_tmp in main:\n",
    "    try:\n",
    "        pos=kkma.pos(main_tmp)\n",
    "        noun=[txt[0] for txt in pos if txt[1] in ['OL','NNG'] and (len(txt[0])>=2 or txt[0] in ('대','중','소'))]\n",
    "        main_noun.append(noun)\n",
    "    except:''\n",
    "all_main_noun=sum(main_noun,[])\n",
    "\n",
    "post_noun=[]\n",
    "for post_tmp in post:\n",
    "    try:\n",
    "        pos=kkma.pos(post_tmp)\n",
    "        noun=[txt[0] for txt in pos if txt[1] in ['OL','NNG'] and (len(txt[0])>=2 or txt[0] in ('대','중','소'))]\n",
    "        post_noun.append(noun)\n",
    "    except: post_noun.append([\"\"])\n",
    "all_post_noun=sum(post_noun,[])\n",
    "\n",
    "comments_noun=[]\n",
    "for i,comments_tmp in enumerate(comments):\n",
    "    comment_noun=[]\n",
    "    for comment in comments_tmp:\n",
    "        try:\n",
    "            pos=kkma.pos(comment)\n",
    "            noun=[txt[0] for txt in pos if txt[1] in ['OL','NNG'] and (len(txt[0])>=2 or txt[0] in ('대','중','소'))]\n",
    "            comment_noun.append(noun)\n",
    "        except:\n",
    "            comment_noun.append([\"\"])\n",
    "    comments_noun.append(sum(comment_noun,[]))\n",
    "all_comments_noun=sum(comments_noun,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 게시글 제목, 내용, 댓글별 단어 출현 횟수 파악 및 모든 게시글의 단어 출현 횟수 파악\n",
    "main_freq=Counter(all_main_noun)\n",
    "post_freq=Counter(all_post_noun)\n",
    "comment_freq=Counter(all_comments_noun)\n",
    "all_freq=Counter(sum([all_main_noun,all_post_noun,all_comments_noun],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상품 구매와 연관된 단어들의 출현 횟수 추출 및 csv파일 저장\n",
    "main_count=count_sort(main_freq,20)\n",
    "post_count=count_sort(post_freq,20)\n",
    "comment_count=count_sort(comment_freq,20)\n",
    "\n",
    "save_csv_dict(main_count,'main_count')\n",
    "save_csv_dict(post_count,'post_count')\n",
    "save_csv_dict(comment_count,'comment_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜별 게시글 수 파악\n",
    "date_notime=[dt.date() for dt in date]\n",
    "date_count=Counter(date_notime)\n",
    "save_csv_dict(date_count,'date_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 게시글 제목, 내용, 댓글별 추출한 주요 단어 중 형태소 분석에서 분리된 단어 결합 및 상품구매와 관련성이 떨어지는 단어 제거\n",
    "except_word=['제가','FMKOREA','RE','아이','오늘','일차','현재','HTTPS','COM','WWW','자체','있음','느낌','기준','이제','본인','경우','포함','최소','유료광고','현금','유저','정도','피파온라인','PC','질문','지금','대리낙찰','게임','생각','가치','얼마','사람','정보통','이번','후기','이유','요즘', '감사', '시간', '가능', '시간', '진짜', '이상']\n",
    "\n",
    "main_r=[\" \".join(noun) for noun in main_noun]\n",
    "post_r=[\" \".join(noun) for noun in post_noun]\n",
    "comment_r=[\" \".join(noun) for noun in comments_noun]\n",
    "\n",
    "main_r=[noun.replace(\"감독 모드\",'감독모드') for noun in main_r]\n",
    "post_r=[noun.replace(\"감독 모드\",'감독모드') for noun in post_r]\n",
    "comment_r=[noun.replace(\"감독 모드\",'감독모드') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"이적 시장\",'이적시장') for noun in main_r]\n",
    "post_r=[noun.replace(\"이적 시장\",'이적시장') for noun in post_r]\n",
    "comment_r=[noun.replace(\"이적 시장\",'이적시장') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"구단 가치\",'구단가치') for noun in main_r]\n",
    "post_r=[noun.replace(\"구단 가치\",'구단가치') for noun in post_r]\n",
    "comment_r=[noun.replace(\"구단 가치\",'구단가치') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"대리 낙찰\",'대리낙찰') for noun in main_r]\n",
    "post_r=[noun.replace(\"대리 낙찰\",'대리낙찰') for noun in post_r]\n",
    "comment_r=[noun.replace(\"대리 낙찰\",'대리낙찰') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"유료 광고\",'유료광고') for noun in main_r]\n",
    "post_r=[noun.replace(\"유료 광고\",'유료광고') for noun in post_r]\n",
    "comment_r=[noun.replace(\"유료 광고\",'유료광고') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"카드 결제\",'카드결제') for noun in main_r]\n",
    "post_r=[noun.replace(\"카드 결제\",'카드결제') for noun in post_r]\n",
    "comment_r=[noun.replace(\"카드 결제\",'카드결제') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"라이브 퍼포먼스\",'라이브퍼포먼스') for noun in main_r]\n",
    "post_r=[noun.replace(\"라이브 퍼포먼스\",'라이브퍼포먼스') for noun in post_r]\n",
    "comment_r=[noun.replace(\"라이브 퍼포먼스\",'라이브퍼포먼스') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"대리 업체\",'대리업체') for noun in main_r]\n",
    "post_r=[noun.replace(\"대리 업체\",'대리업체') for noun in post_r]\n",
    "comment_r=[noun.replace(\"대리 업체\",'대리업체') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"고객 센터\",'고객센터') for noun in main_r]\n",
    "post_r=[noun.replace(\"고객 센터\",'고객센터') for noun in post_r]\n",
    "comment_r=[noun.replace(\"고객 센터\",'고객센터') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"알파 거래\",'알파거래') for noun in main_r]\n",
    "post_r=[noun.replace(\"알파 거래\",'알파거래') for noun in post_r]\n",
    "comment_r=[noun.replace(\"알파 거래\",'알파거래') for noun in comment_r]\n",
    "\n",
    "main_r=[noun.replace(\"마일 스톤\",'마일스톤') for noun in main_r]\n",
    "post_r=[noun.replace(\"마일 스톤\",'마일스톤') for noun in post_r]\n",
    "comment_r=[noun.replace(\"마일 스톤\",'마일스톤') for noun in comment_r]\n",
    "\n",
    "for except_w in except_word:\n",
    "    main_r=[noun.replace(except_w,'') for noun in main_r]\n",
    "    post_r=[noun.replace(except_w,'') for noun in post_r]\n",
    "    comment_r=[noun.replace(except_w,'') for noun in comment_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 단어들, 날짜, 조회수, 추천수, 댓글수 저장\n",
    "posts=pd.DataFrame(np.transpose(np.array([list(map(str,date_notime)),view_num,recommend_num, comment_num,main_r,post_r, comment_r])))\n",
    "posts.to_csv(\"C:/Users/wjdgh/OneDrive/바탕 화면/과제 A/A-2/excel/posts.csv\",header=False,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
